---
layout: page
title: Published Articles
permalink: /articles/
published: true
---

### 2018

 <center><h4 id="An Improved CNN Steganalysis Architecture Based on “Catalyst Kernels” and Transfer Learning"> #3 - An Improved CNN Steganalysis Architecture Based on “Catalyst Kernels” and Transfer Learning </h4></center>

 <br/>

- **Published in** : [_Economy. Emerging Technologies and Business Innovation pp 119-128_](https://link.springer.com/chapter/10.1007/978-3-319-97749-2_9)
- **Authors** : Rabii ElBeji, Marwa Saidi, Houcemeddine Hermassi, Rhouma Rhouma
- **Project code**: [SteganalysisCNN](https://github.com/rabi3elbeji/SteganalysisCNN)

<ul style="font-size:14px">
In recent years, the interest of using model architectures based on the Convolutional Neural Networks in steganalysis has been rapidly increasing. Regarding the success of deep learning in the field of imaging analysis. Previous approaches have focused on proposing complex architectures with large sizes of images rather than simple models. In this work, we propose a more adjustable flexible architecture with the use of small size images. The robustness of our method is based on using a set of High Pass Filters (HPF) to extract the residual noise on one hand and exploiting the concept of Transfer Learning ensuring the propagation of optimal weights on the other hand. Three state-of-the-art steganographic algorithms in the spatial domain: WOW, S-UNIWARD, and HUGO are used to evaluate the effectiveness of our classification method. Our proposed technique shows an accelerated convergence for the low payloads and provides a better detection accuracy for the high payloads with a classification accuracy rate crossing 96%.
</ul>



### 2016

<center><h4 id="A Comparative Study of Vision-Based Traffic Signs Recognition Methods"> #2 - A Comparative Study of Vision-Based Traffic Signs Recognition Methods </h4></center>

<br/>

- **Published in** : [Image Analysis and Recognition pp 341-348](https://link.springer.com/chapter/10.1007/978-3-319-41501-7_39)
- **Authors** : Nadra Ben Romdhane, Hazar Mliki, Rabii El Beji, Mohamed Hammami

<ul style="font-size:14px">
Traffic signs recognition is an important component in driver assistance systems as it helps driving under safety regulations. The aim of this work is to propose a vision based traffic sign recognition. In the recognition process, we detect the potential traffic signs regions using monocular color based segmentation. Afterwards, we identify the traffic sign class using its HoG features and
the SVM classifier. As shown experimentally, compared to leading methods from the literature under complex conditions, our method has a higher efficiency.
</ul>

<br/>


<center><h4 id="Combined 2d/3d Traffic Signs Recognition and Distance Estimation"> #1 - Combined 2d/3d Traffic Signs Recognition and Distance Estimation </h4></center>

<br/>

- **Published in** : [Image Analysis and Recognition pp 341-348](http://ieeexplore.ieee.org/document/7535410/?reload=true)
- **Authors** : Nadra Ben Romdhane, Hazar Mliki, Rabii El Beji, Mohamed Hammami

<ul style="font-size:14px">
Accidents caused by reduced concentration of drivers on traffic signs indications continue to represent an important part of accident-prone situations. Face to this threat, our work aims to develop a vision-based traffic sign recognition method based on a two-step recognition and 3D distance computing module. Firstly, a monocular color based segmentation method is applied to generate traffic sign candidates. Then, HoG features are applied to encode the detected traffic signs and compute the feature vector. This vector is used as an input to a SVM classifier to identify the
traffic sign class. Secondly, a dense disparity map between the left and right images is created for the recognized traffic sign region to compute its distance to the vehicle carrying the stereovision. Our method affords high precision rates under different weather conditions. Moreover, it operates with a timing that is reasonable for real-time applications. The obtained results, compared to leading methods from the literature, prove the efficiency of our proposed method.
</ul>
